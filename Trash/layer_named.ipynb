{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProximalOperatorM(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, in_channels: int) -> None:\n",
    "\n",
    "#         super(ProximalOperatorM, self).__init__()\n",
    "\n",
    "#         self.in_channels = in_channels\n",
    "#         self.num_features = in_channels // 2\n",
    "        \n",
    "#         conv_X = torch.nn.Conv2d(self.in_channels, self.num_features, (3, 3), padding='same')\n",
    "#         activation_X = torch.nn.ReLU()\n",
    "#         self.conv = torch.nn.Sequential([conv_X, activation_X])\n",
    "\n",
    "        \n",
    "\n",
    "#         for i in range(0, 5):\n",
    "#             for j in range(1, 3):\n",
    "#                 # Create conv_1 and conv_2\n",
    "#                 name = 'iteration_'+str(i)+':'+'conv'+str(j)\n",
    "#                 conv_X = torch.nn.Conv2d(self.num_features, self.num_features, (3, 3), padding='same')\n",
    "#                 activation_X = torch.nn.ReLU()\n",
    "#                 sequence = torch.nn.Sequential([conv_X, activation_X])\n",
    "#                 self.add_module(name=name, module=sequence)\n",
    "\n",
    "#         self.out = torch.nn.Conv2d(self.num_features, self.in_channels, (3, 3), padding='same')\n",
    "\n",
    "\n",
    "#     def forward(self, image):\n",
    "\n",
    "#         out_conv = self.conv(image)\n",
    "\n",
    "#         for i in range(0, 5):\n",
    "            \n",
    "#             conv_1 = self.get_submodule(target='iteration_'+str(i)+':'+'conv_'+str(1))\n",
    "#             conv_2 = self.get_submodule(target='iteration_'+str(i)+':'+'conv_'+str(2))\n",
    "\n",
    "#             out_conv_1 = conv_1(out_conv)\n",
    "#             out_conv_2 = conv_2(out_conv_1)\n",
    "#             out_conv = out_conv + out_conv_2\n",
    "\n",
    "#         out_out = self.out(out_conv)\n",
    "\n",
    "#         return out_out      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ProximalOperatorO(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, in_channels: int, num_features: int) -> None:\n",
    "\n",
    "#         super(ProximalOperatorO, self).__init__()\n",
    "\n",
    "#         self.in_channels = in_channels\n",
    "#         self.num_features = num_features\n",
    "        \n",
    "#         conv_X = torch.nn.Conv2d(self.in_channels, self.num_features, (3, 3), padding='same')\n",
    "#         activation_X = torch.nn.ReLU()\n",
    "#         self.conv = torch.nn.Sequential([conv_X, activation_X])\n",
    "\n",
    "#         self.out = torch.nn.Conv2d(self.in_channels, (3, 3), padding='same')\n",
    "\n",
    "#         for i in range(0, 5):\n",
    "#             for j in range(1, 3):\n",
    "#                 # Create conv_1 and conv_2\n",
    "#                 name = 'iteration_'+str(i)+':'+'conv'+str(j)\n",
    "#                 conv_X = torch.nn.Conv2d(self.in_channels, self.num_features, (3, 3), padding='same')\n",
    "#                 activation_X = torch.nn.ReLU()\n",
    "#                 sequence = torch.nn.Sequential([conv_X, activation_X])\n",
    "#                 self.add_module(name=name, module=sequence)\n",
    "\n",
    "\n",
    "#     def forward(self, image):\n",
    "\n",
    "#         out_conv = self.conv(image)\n",
    "\n",
    "#         for i in range(0, 5):\n",
    "            \n",
    "#             conv_1 = self.get_submodule(target='iteration_'+str(i)+':'+'conv_'+str(1))\n",
    "#             conv_2 = self.get_submodule(target='iteration_'+str(i)+':'+'conv_'+str(2))\n",
    "\n",
    "#             out_conv_1 = conv_1(out_conv)\n",
    "#             out_conv_2 = conv_2(out_conv_1)\n",
    "#             out_conv = out_conv + out_conv_2\n",
    "\n",
    "#         out_out = self.out(out_conv)\n",
    "#         B = out_out[:, :, :, 0:1]\n",
    "#         Z = out_out[:, :, :, 1:self.in_channels]\n",
    "\n",
    "#         return B, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProximalOperator(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels: int, num_features: int) -> None:\n",
    "\n",
    "        super(ProximalOperator, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_features = num_features\n",
    "        \n",
    "        conv_X = torch.nn.Conv2d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.num_features,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "        activation_X = torch.nn.ReLU()\n",
    "        self.conv = torch.nn.Sequential(conv_X, activation_X)\n",
    "\n",
    "        for i in range(0, 5):\n",
    "            for j in range(1, 3):\n",
    "                # Create conv_1 and conv_2\n",
    "                name = 'iteration_'+str(i)+':'+'conv_'+str(j)\n",
    "                conv_X =  conv_X = torch.nn.Conv2d(\n",
    "                    in_channels=self.num_features,\n",
    "                    out_channels=self.num_features,\n",
    "                    kernel_size=(3, 3),\n",
    "                    padding='same'\n",
    "                )\n",
    "                activation_X = torch.nn.ReLU()\n",
    "                sequence = torch.nn.Sequential(conv_X, activation_X)\n",
    "                self.add_module(name=name, module=sequence)\n",
    "\n",
    "        self.out = torch.nn.Conv2d(\n",
    "            in_channels=self.num_features,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, image):\n",
    "\n",
    "        out_conv = self.conv(image)\n",
    "\n",
    "        for i in range(0, 5):\n",
    "            \n",
    "            conv_1 = self.get_submodule(target='iteration_'+str(i)+':'+'conv_'+str(1))\n",
    "            conv_2 = self.get_submodule(target='iteration_'+str(i)+':'+'conv_'+str(2))\n",
    "\n",
    "            out_conv_1 = conv_1(out_conv)\n",
    "            out_conv_2 = conv_2(out_conv_1)\n",
    "            out_conv = out_conv + out_conv_2\n",
    "\n",
    "        out_out = self.out(out_conv)\n",
    "\n",
    "        return out_out\n",
    "\n",
    "\n",
    "class Prox_M(ProximalOperator):\n",
    "\n",
    "    def __init__(self, in_channels: int) -> None:\n",
    "        super(Prox_M, self).__init__(in_channels, in_channels // 2)\n",
    "\n",
    "class Prox_O(ProximalOperator):\n",
    "\n",
    "    def __init__(self, in_channels: int, num_features: int) -> None:\n",
    "        super(Prox_O, self).__init__(in_channels, num_features)\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        out_out = super().forward(image)\n",
    "        B = out_out[:, 0:1, :, :]\n",
    "        Z = out_out[:, 1:self.in_channels, :, :]\n",
    "        return B, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unfolding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels: int, num_features: int = 48, iterations: int = 10) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "            in_channels : img.shape[2]\n",
    "                + grey level => in_channels=1\n",
    "                + rgb color => in_channels=3\n",
    "        \"\"\"\n",
    "\n",
    "        super(Unfolding, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_features = num_features\n",
    "        self.iterations = iterations\n",
    "\n",
    "        # Initial\n",
    "        self.O_0 = torch.nn.Conv2d(\n",
    "            in_channels=self.in_channels, \n",
    "            out_channels=self.num_features,\n",
    "            kernel_size=(3, 3),\n",
    "            padding='same'\n",
    "        )\n",
    "\n",
    "        self.add_module(\n",
    "            name='O_0',\n",
    "            module=self.O_0\n",
    "        )\n",
    "\n",
    "        self.stepO = torch.tensor(data=0.1, dtype=torch.float, requires_grad=True)\n",
    "        self.stepM = torch.tensor(data=0.1, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "        self.prox_M = Prox_M(in_channels=self.num_features*3)\n",
    "        self.add_module(name='Prox_M', module=self.prox_M)\n",
    "\n",
    "        self.prox_O = Prox_O(in_channels=self.num_features+self.in_channels, num_features=self.num_features)\n",
    "        self.add_module(name='Prox_O', module=self.prox_O)\n",
    "\n",
    "        for i in range(0, iterations):\n",
    "            self.__init_iteration(i)\n",
    "\n",
    "\n",
    "    def __init_iteration(self, i: int) -> None:\n",
    "\n",
    "        self.add_module(\n",
    "            name='iteration_'+str(i)+':X1',\n",
    "            module=torch.nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "        )\n",
    "\n",
    "        self.add_module(\n",
    "            name='iteration_'+str(i)+':X2',\n",
    "            module=torch.nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "        )\n",
    "\n",
    "        self.add_module(\n",
    "            name='iteration_'+str(i)+':X4',\n",
    "            module=torch.nn.Conv2d(in_channels=self.in_channels, out_channels=self.num_features, kernel_size=(3, 3), dilation=(4, 4), padding='same', bias=False)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.add_module(\n",
    "            name='iteration_'+str(i)+':X11',\n",
    "            module=torch.nn.Conv2d(in_channels=self.num_features, out_channels=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "        )\n",
    "\n",
    "        self.add_module(\n",
    "            name='iteration_'+str(i)+':X22',\n",
    "            module=torch.nn.Conv2d(in_channels=self.num_features, out_channels=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "        )\n",
    "\n",
    "        self.add_module(\n",
    "            name='iteration_'+str(i)+':X44',\n",
    "            module=torch.nn.Conv2d(in_channels=self.num_features, out_channels=self.num_features, kernel_size=(3, 3), dilation=(4, 4), padding='same', bias=False)\n",
    "        )\n",
    "\n",
    "        if 0 < i :\n",
    "\n",
    "            self.add_module(\n",
    "                name='iteration_'+str(i)+':X111',\n",
    "                module=torch.nn.Conv2d(in_channels=self.num_features, out_channels=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "            )\n",
    "        \n",
    "            self.add_module(\n",
    "                name='iteration_'+str(i)+':X222',\n",
    "                module=torch.nn.Conv2d(in_channels=self.num_features, out_channels=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "            )\n",
    "            \n",
    "            self.add_module(\n",
    "                name='iteration_'+str(i)+':X444',\n",
    "                module=torch.nn.Conv2d(in_channels=self.num_features, out_channels=self.num_features, kernel_size=(3, 3), dilation=(4, 4), padding='same', bias=False)\n",
    "            )\n",
    "\n",
    "    def __apply_layer(self, iter: int, name: str, input: torch.Tensor) -> torch.Tensor:\n",
    "        layer = self.get_submodule(target='iteration_'+str(iter)+':'+name)\n",
    "        return layer(input)\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        # Initial\n",
    "        out_O_0 = self.O_0(image)\n",
    "        tmp = torch.concat([out_O_0, image], 1)\n",
    "        O_previous, Z = self.prox_O(tmp)\n",
    "        H = image - O_previous\n",
    "\n",
    "        # Iteration 0\n",
    "\n",
    "        X_1 = self.__apply_layer(iter=0, name='X1', input=H)\n",
    "        X_2 = self.__apply_layer(iter=0, name='X2', input=H)\n",
    "        X_4 = self.__apply_layer(iter=0, name='X4', input=H)\n",
    "        \n",
    "        M = self.prox_M(torch.concat([X_1, X_2, X_4], 1))\n",
    "  \n",
    "        X_1 = self.__apply_layer(iter=0, name='X11', input=M[:, 0:self.num_features, :, :])\n",
    "        X_2 = self.__apply_layer(iter=0, name='X22', input=M[:, self.num_features:self.num_features*2, :, :])\n",
    "        X_4 = self.__apply_layer(iter=0, name='X44', input=M[:, self.num_features*2:self.num_features*3, :, :])\n",
    "    \n",
    "        h_current = torch.concat([X_1, X_2, X_4], 1)\n",
    "        # H_current = torch.sum(h_current, h_current.dim(), keepdim=True)\n",
    "        H_current = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "        O_current = image-H_current\n",
    "        tmp = torch.concat([Z, self.stepO*O_current+(1.0-self.stepO)*O_previous], 1)\n",
    "\n",
    "        O_current, Z = self.prox_O(tmp)\n",
    "\n",
    "        # Iteration 1 to 9\n",
    "        for i in range(1, self.iterations):\n",
    "\n",
    "            O_previous = O_current\n",
    "            H = image - O_previous\n",
    "\n",
    "            X_1 = self.__apply_layer(iter=i, name='X11', input=M[:, 0:self.num_features, :, :])\n",
    "            X_2 = self.__apply_layer(iter=i, name='X22', input=M[:, self.num_features:self.num_features*2, :, :])\n",
    "            X_4 = self.__apply_layer(iter=i, name='X44', input=M[:, self.num_features*2:self.num_features*3, :, :])\n",
    "\n",
    "            H_star = torch.concat([X_1, X_2, X_4], 1)\n",
    "            # H_current = torch.sum(h_current, h_current.dim(), keepdim=True)\n",
    "            H_star = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "            X_1 = self.__apply_layer(iter=i, name='X1', input=H_star-H)\n",
    "            X_2 = self.__apply_layer(iter=i, name='X2', input=H_star-H)\n",
    "            X_4 = self.__apply_layer(iter=i, name='X4', input=H_star-H)\n",
    "\n",
    "            # stepM = self.get_submodule(target='iteration_'+str(i)+':stepM')\n",
    "            M = self.prox_M(M-self.stepM*torch.concat([X_1, X_2, X_4], 1))\n",
    "\n",
    "            X_1 = self.__apply_layer(iter=i, name='X111', input=M[:, 0:self.num_features, :, :])\n",
    "            X_2 = self.__apply_layer(iter=i, name='X222', input=M[:, self.num_features:self.num_features*2, :, :])\n",
    "            X_4 = self.__apply_layer(iter=i, name='X444', input=M[:, self.num_features*2:self.num_features*3, :, :])\n",
    "\n",
    "            h_current = torch.concat([X_1, X_2, X_4], 1)\n",
    "            # H_current = torch.sum(h_current, h_current.dim(), keepdim=True)\n",
    "            H_current = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "            O_current = image-H_current\n",
    "            tmp = torch.concat([Z, self.stepO*O_current+(1.0-self.stepO)*O_previous], 1)\n",
    "            O_current, Z = self.prox_O(tmp)\n",
    "\n",
    "        final_out = O_current\n",
    "        \n",
    "        return final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset customization : https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n",
    "import torchvision\n",
    "import pathlib\n",
    "import os\n",
    "import torch.nn.functional\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root_dir: pathlib.Path) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (pathlib.Path): Directory with all the images.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.root_dir: pathlib.Path = root_dir\n",
    "        self.image_names: list[pathlib.Path] = [ filename.stem for filename in map(lambda e : pathlib.Path(e), os.listdir(root_dir / 'Artifacts')) ]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        filename_artifact: pathlib.Path = self.root_dir / 'Artifacts' / (self.image_names[index] + '.jpg')\n",
    "        image_artifact_string: torch.Tensor = torchvision.io.read_file(str(filename_artifact))\n",
    "        image_artifact_decoded: torch.Tensor = torchvision.io.decode_jpeg(input=image_artifact_string, mode=torchvision.io.ImageReadMode.GRAY) / 255.0\n",
    "\n",
    "        filename_result: pathlib.Path = self.root_dir / 'Results' / (self.image_names[index] + '.png')\n",
    "        image_result_string: torch.Tensor = torchvision.io.read_file(str(filename_result))\n",
    "        image_result_decoded: torch.Tensor = torchvision.io.decode_png(input=image_result_string, mode=torchvision.io.ImageReadMode.GRAY) / 255.0\n",
    "\n",
    "        image_artifact_decoded = torch.nn.functional.max_pool2d(image_artifact_decoded, (2,2))\n",
    "        image_result_decoded = torch.nn.functional.max_pool2d(image_result_decoded, (2,2))\n",
    "\n",
    "        return image_artifact_decoded, image_result_decoded\n",
    "        # return image_artifact_decoded.squeeze(), image_result_decoded.squeeze()\n",
    "        \n",
    "\n",
    "        # return { 'Artifacts' : image_artifact_decoded, 'Results' : image_result_decoded }\n",
    "\n",
    "dataset: ImageDataset = ImageDataset(root_dir=pathlib.Path('./phantom-datas'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Unfolding(in_channels=1, num_features=48, iterations=10)\n",
    "# O_0 = torch.nn.Conv2d(1, 48, (3, 3), padding='same')\n",
    "# O_0(dataset[0][0])\n",
    "# model.forward(dataset[0][0])\n",
    "# print(O_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ignite.engine\n",
    "import torch.optim\n",
    "import torch.optim.lr_scheduler\n",
    "import ignite.contrib.handlers\n",
    "\n",
    "\n",
    "def split_dataset(dataset: ImageDataset, train_size: float) -> tuple[ImageDataset, ImageDataset]:\n",
    "    n = len(dataset)\n",
    "    train_size = int(0.8*n)\n",
    "    test_size = n-train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def get_dataloaders(config: dict[str, str|int]) -> tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    dataset_full = ImageDataset(pathlib.Path(config['dataset_path']))\n",
    "    train_dataset, test_dataset = split_dataset(dataset=dataset_full, train_size=config.get('train_size', 0.8))\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.get('batch_size', 32),\n",
    "        shuffle=config.get('shuffle', False)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config.get('batch_size', 32))\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def initialize(config: dict[str, str|int|dict]):\n",
    "\n",
    "    config_model: dict = config.get('model')\n",
    "\n",
    "    model = Unfolding(\n",
    "        in_channels=config_model.get('input_channels', 1),\n",
    "        num_features=config_model.get('num_features', 48),\n",
    "        iterations=config_model.get('iterations', 10)\n",
    "    )\n",
    "   \n",
    "    optimizer = torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr = config.get('learning_rate', 0.001)\n",
    "    )\n",
    "\n",
    "    # MAE\n",
    "    criterion = torch.nn.L1Loss()\n",
    "\n",
    "    # # https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html\n",
    "    # le = config[\"num_iters_per_epoch\"]\n",
    "    # lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=le, gamma=0.9)\n",
    "    lr_scheduler = None\n",
    "\n",
    "    return model, optimizer, criterion, lr_scheduler\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model' : {\n",
    "        'input_channels' : 1,\n",
    "        'iterations' : 10,\n",
    "        'num_features' : 48\n",
    "    },\n",
    "    'dataset_path' : './phantom-datas',\n",
    "    'train_size' : 0.8,\n",
    "    'batch_size' : 1,\n",
    "    'output_path' : 'output',\n",
    "    'shuffle' : True,\n",
    "    'learning_rate' : 0.001,\n",
    "    'max_epochs' : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_step(\n",
    "    model: torch.nn.Module, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    criterion,\n",
    "    lr_scheduler: torch.optim.lr_scheduler.StepLR = None\n",
    "):\n",
    "\n",
    "    # model, optimizer, criterion, lr_scheduler = initialize(config)\n",
    "    # Define any training logic for iteration update\n",
    "    def train_step(engine, batch):\n",
    "        \n",
    "        # x, y = batch[0].to(idist.device()), batch[1].to(idist.device())\n",
    "        # artifact, result = batch[0], batch[1]\n",
    "        artifacts, results = batch\n",
    "\n",
    "        model.train()\n",
    "        predictions = model(artifacts)\n",
    "        loss: torch.Tensor = criterion(predictions, results)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if not(lr_scheduler is None):\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        output = {\n",
    "            'prediction' : predictions,\n",
    "            'result' : results,\n",
    "            'loss' : loss.item()\n",
    "        }\n",
    "\n",
    "        return output\n",
    "\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluate_function(\n",
    "    model: torch.nn.Module\n",
    "):\n",
    "\n",
    "    # model, optimizer, criterion, lr_scheduler = initialize(config)\n",
    "    # Define any evaluation\n",
    "    def eval_step(engine, batch):\n",
    "        \n",
    "        # x, y = batch[0].to(idist.device()), batch[1].to(idist.device())\n",
    "        # artifact, result = batch[0], batch[1]\n",
    "        artifacts, results = batch\n",
    "\n",
    "        model.eval() # model.train(False)\n",
    "        predictions = model(artifacts)\n",
    "        \n",
    "        output = {\n",
    "            'prediction' : predictions, \n",
    "            'result' : results\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "\n",
    "    return eval_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, validation_loader = get_dataloaders(config)\n",
    "model, optimizer, criterion, lr_scheduler = initialize(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ignite.metrics\n",
    "\n",
    "# Define trainer engine and Setup model trainer\n",
    "train_step = create_train_step(model, optimizer, criterion, lr_scheduler)\n",
    "trainer = ignite.engine.Engine(train_step)\n",
    "\n",
    "loss_history: list = []\n",
    "def update_loss_history(engine: ignite.engine.Engine, loss_history: list):\n",
    "    loss_history.append(engine.state.output['loss'])\n",
    "\n",
    "def print_logs(engine: ignite.engine.Engine):\n",
    "    strp = 'Epoch [{}/{}] : Loss {:.2f}'\n",
    "    print(\n",
    "        strp.format(\n",
    "            engine.state.epoch,\n",
    "            engine.state.epoch_length,\n",
    "            engine.state.iteration,\n",
    "            engine.state.output['loss']\n",
    "        )\n",
    "    )\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.EPOCH_COMPLETED,\n",
    "    # Callback\n",
    "    update_loss_history,\n",
    "    # Parameters of callback\n",
    "    loss_history\n",
    ")\n",
    "\n",
    "# trainer.add_event_handler(\n",
    "#     ignite.engine.Events.GET_BATCH_COMPLETED,\n",
    "#     # Callback\n",
    "#     print_logs,\n",
    "# )\n",
    "\n",
    "# Add progress bar showing batch loss value adn some metrics\n",
    "pbar = ignite.contrib.handlers.ProgressBar(\n",
    "    persist=True\n",
    ")\n",
    "pbar.attach(\n",
    "    engine=trainer, \n",
    "    output_transform=lambda output: {'loss': output['loss']}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_function = create_evaluate_function(model)\n",
    "evaluator = ignite.engine.Engine(evaluate_function)\n",
    "\n",
    "\n",
    "# METRICS CONFIG\n",
    "## https://pytorch.org/ignite/metrics.html\n",
    "## https://pytorch.org/ignite/generated/ignite.metrics.RunningAverage.html\n",
    "\n",
    "### MAE METRICS\n",
    "\n",
    "output_transform = lambda output: (output['prediction'], output['result'])\n",
    "\n",
    "\n",
    "### MAE METRICS\n",
    "\n",
    "mae = ignite.metrics.MeanAbsoluteError(\n",
    "    output_transform=output_transform\n",
    ")\n",
    "\n",
    "avg_mae = ignite.metrics.RunningAverage(src=mae)\n",
    "\n",
    "mae.attach(engine=evaluator, name='mae')\n",
    "avg_mae.attach(engine=evaluator, name='avg_mae')\n",
    "\n",
    "### MSE METRICS\n",
    "\n",
    "mse = ignite.metrics.MeanSquaredError(\n",
    "    output_transform=output_transform\n",
    ")\n",
    "avg_mse = ignite.metrics.RunningAverage(src=mse)\n",
    "\n",
    "mse.attach(engine=evaluator, name='mse')\n",
    "avg_mse.attach(engine=evaluator, name='avg_mse')\n",
    "\n",
    "       \n",
    "\n",
    "# HANDLERS CONFIG\n",
    "## https://pytorch.org/ignite/generated/ignite.engine.engine.Engine.html#ignite.engine.engine.Engine.add_event_handler\n",
    "\n",
    "\n",
    "def update_history_metrics(\n",
    "    engine: ignite.engine.Engine, \n",
    "    evaluator: ignite.engine.Engine,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    history: dict[str, list],\n",
    "    mode: str\n",
    ") -> None:\n",
    "\n",
    "    evaluator.run(dataloader, max_epochs=1)\n",
    "\n",
    "    no_epoch = engine.state.epoch\n",
    "    \n",
    "    metrics = evaluator.state.metrics\n",
    "    mae = metrics['mae']\n",
    "    avg_mae = metrics['avg_mae']\n",
    "    mse = metrics['mse']\n",
    "    avg_mse = metrics['avg_mse']\n",
    "    str_print = mode + ' Results - Epoch {} - mae: {:.2f} Avg mae: {:.2f} mse: {:.2f} Avg mse: {:.2f}'\n",
    "\n",
    "    # Print logs\n",
    "    print(str_print.format(no_epoch, mae, avg_mae, mse, avg_mse))\n",
    "\n",
    "    # Update history\n",
    "    for key in evaluator.state.metrics.keys():\n",
    "        history[key].append(evaluator.state.metrics[key])\n",
    "\n",
    "\n",
    "validation_history = {\n",
    "    'mae' : [],\n",
    "    'avg_mae' : [],\n",
    "    'mse' : [],\n",
    "    'avg_mse' : []\n",
    "}\n",
    "\n",
    "training_history = {\n",
    "    'mae' : [],\n",
    "    'avg_mae' : [],\n",
    "    'mse' : [],\n",
    "    'avg_mse' : [],\n",
    "}\n",
    "\n",
    "# For each epoch completed:\n",
    "# - we keep metrics\n",
    "# - we print metrics\n",
    "\n",
    "## Evaluation on datas using for training\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.ITERATION_COMPLETED,\n",
    "    # Callback\n",
    "    update_history_metrics,\n",
    "    # Parameters of callback\n",
    "    evaluator, \n",
    "    train_loader, \n",
    "    training_history,\n",
    "    'Training Datas'\n",
    ")\n",
    "\n",
    "## Evaluation on datas using for validation\n",
    "trainer.add_event_handler(\n",
    "    ignite.engine.Events.ITERATION_COMPLETED,\n",
    "    # Callback\n",
    "    update_history_metrics,\n",
    "    # Parameters of callback\n",
    "    evaluator, \n",
    "    validation_loader, \n",
    "    validation_history,\n",
    "    'Validation Datas'\n",
    ")\n",
    "\n",
    "# Add progress bar showing batch loss value adn some metrics\n",
    "pbar = ignite.contrib.handlers.ProgressBar(\n",
    "    persist=True\n",
    ")\n",
    "pbar.attach(\n",
    "    engine=evaluator\n",
    "    # metric_names=['mae', 'avg_mae', 'mse', 'avg_mse']\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: [7/7] 100%|██████████ [01:23<00:00]00:00<?]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Datas Results - Epoch 1 - mae: 7640.21 Avg mae: 7640.32 mse: 1894.67 Avg mse: 1895.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: [2/2] 100%|██████████ [00:12<00:00]\n",
      "Iteration: [1/1] 100%|██████████, loss=0.241 [02:07<?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Datas Results - Epoch 1 - mae: 7650.71 Avg mae: 7647.26 mse: 1899.01 Avg mse: 1897.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 1\n",
       "\tepoch: 1\n",
       "\tepoch_length: 1\n",
       "\tmax_epochs: 1\n",
       "\toutput: <class 'dict'>\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training(config)\n",
    "trainer.run(train_loader, epoch_length=config.get('max_epochs', 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/ignite/blob/master/examples/notebooks/VAE.ipynb\n",
    "# plt.plot(range(20), training_history['bce'], 'dodgerblue', label='training')\n",
    "# plt.plot(range(20), validation_history['bce'], 'orange', label='validation')\n",
    "# plt.xlim(0, 20);\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('BCE')\n",
    "# plt.title('Binary Cross Entropy on Training/Validation Set')\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Unfolding(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, in_channels: int, num_features: int = 48, iterations: int = 10) -> None:\n",
    "\n",
    "#         \"\"\"\n",
    "#             in_channels : img.shape[2]\n",
    "#                 + grey level => in_channels=1\n",
    "#                 + rgb color => in_channels=3\n",
    "#         \"\"\"\n",
    "\n",
    "#         super(Unfolding, self).__init__()\n",
    "\n",
    "#         self.in_channels = in_channels\n",
    "#         self.num_features = num_features\n",
    "#         self.iterations = iterations\n",
    "\n",
    "#         # Initial\n",
    "#         # self.O_0 = torch.nn.Conv2d(self.in_channels, self.num_features, (3, 3), 'same')\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='O_0',\n",
    "#             module=torch.nn.Conv2d(self.in_channels, self.num_features, (3, 3), 'same')\n",
    "#         )\n",
    "\n",
    "#         self.stepO = torch.tensor(data=0.1, dtype=torch.float, requires_grad=True)\n",
    "#         self.stepM = torch.tensor(data=0.1, dtype=torch.float, requires_grad=True)\n",
    "\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='Prox_M', \n",
    "#             module=Prox_M(in_channels=self.num_features)\n",
    "#         )\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='Prox_O', \n",
    "#             module=Prox_O(in_channels=self.num_features*3, num_features=self.num_features)\n",
    "#         )\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "#         # for i in range(0, iterations):\n",
    "            \n",
    "            \n",
    "        \n",
    "#         # for i in range(2, iterations-1):\n",
    "#         #     pass\n",
    "        \n",
    "    \n",
    "\n",
    "#     # def __init_iteration_0(self) -> None:\n",
    "\n",
    "#     #     self.add_module(\n",
    "#     #         name='iteration_0:X1',\n",
    "#     #         module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "#     #     )\n",
    "#     #     self.add_module(\n",
    "#     #         name='iteration_0:X11',\n",
    "#     #         module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "#     #     )\n",
    "\n",
    "#     #     self.add_module(\n",
    "#     #         name='iteration_0:X2',\n",
    "#     #         module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "#     #     )\n",
    "#     #     self.add_module(\n",
    "#     #         name='iteration_0:X22',\n",
    "#     #         module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "#     #     )\n",
    "\n",
    "#     #     self.add_module(\n",
    "#     #         name='iteration_0:X4',\n",
    "#     #         module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "#     #     )\n",
    "#     #     self.add_module(\n",
    "#     #         name='iteration_0:X44',\n",
    "#     #         module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "#     #     )\n",
    "\n",
    "#     def __init_iteration_i(self, i: int) -> None:\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='iteration_'+str(i)+':X1',\n",
    "#             module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "#         )\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='iteration_'+str(i)+':X2',\n",
    "#             module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "#         )\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='iteration_'+str(i)+':X4',\n",
    "#             module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(4, 4), padding='same', bias=False)\n",
    "#         )\n",
    "\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='iteration_'+str(i)+':X11',\n",
    "#             module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "#         )\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='iteration_'+str(i)+':X22',\n",
    "#             module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "#         )\n",
    "\n",
    "#         self.add_module(\n",
    "#             name='iteration_'+str(i)+':X44',\n",
    "#             module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(4, 4), padding='same', bias=False)\n",
    "#         )\n",
    "\n",
    "#         if 0 < i :\n",
    "\n",
    "#             self.add_module(\n",
    "#                 name='iteration_'+str(i)+':X111',\n",
    "#                 module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(1, 1), padding='same', bias=False)\n",
    "#             )\n",
    "        \n",
    "#             self.add_module(\n",
    "#                 name='iteration_'+str(i)+':X222',\n",
    "#                 module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(2, 2), padding='same', bias=False)\n",
    "#             )\n",
    "            \n",
    "#             self.add_module(\n",
    "#                 name='iteration_'+str(i)+':X444',\n",
    "#                 module=torch.nn.Conv2d(in_channels=self.num_features, num_features=self.num_features, kernel_size=(3, 3), dilation=(4, 4), padding='same', bias=False)\n",
    "#             )\n",
    "\n",
    "#     def __apply_layer(self, iter: int, name: str, input: torch.Tensor) -> torch.Tensor:\n",
    "#         layer = self.get_submodule(target='iteration_'+str(iter)+':'+name)\n",
    "#         return layer(input)\n",
    "\n",
    "\n",
    "#     def forward(self, image):\n",
    "        \n",
    "#         # Initial\n",
    "#         out_O_0 = self.O_0(image)\n",
    "#         tmp = torch.concat([out_O_0, image], -1)\n",
    "#         O_previous, Z = self.prox_O(tmp)\n",
    "#         H = image - O_previous\n",
    "\n",
    "#         # Iteration 0\n",
    "\n",
    "#         X_1 = self.__apply_layer(iter=0, name='X1', input=H)\n",
    "#         X_2 = self.__apply_layer(iter=0, name='X2', input=H)\n",
    "#         X_4 = self.__apply_layer(iter=0, name='X4', input=H)\n",
    "        \n",
    "#         M = self.__apply_layer(iter=0, name='Prox_M', input=torch.concat([X_1, X_2, X_4], -1))\n",
    "  \n",
    "#         X_1 = self.__apply_layer(iter=0, name='X11', input=M[:, :, :, 0:self.num_features])\n",
    "#         X_2 = self.__apply_layer(iter=0, name='X22', input=M[:, :, :, self.num_features:self.num_features*2])\n",
    "#         X_4 = self.__apply_layer(iter=0, name='X44', input=M[:, :, :, self.num_features*2:self.num_features*3])\n",
    "    \n",
    "#         h_current = torch.concat([X_1, X_2, X_4], -1)\n",
    "#         # H_current = torch.sum(h_current, h_current.dim(), keepdim=True)\n",
    "#         H_current = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "#         O_current = image-H_current\n",
    "#         stepO = self.get_submodule(target='iteration_0:stepO')\n",
    "#         tmp = torch.concat([Z, stepO*O_current+(1.0-stepO)*O_previous], -1)\n",
    "\n",
    "#         O_current, Z = self.__apply_layer(iter=0, name='Prox_O', input=tmp)\n",
    "\n",
    "#         # Iteration 1 to 9\n",
    "#         for i in range(1, self.iterations):\n",
    "\n",
    "#             O_previous = O_current\n",
    "#             H = image - O_previous\n",
    "\n",
    "#             X_1 = self.__apply_layer(iter=i, name='X11', input=M[:, :, :, 0:self.num_features])\n",
    "#             X_2 = self.__apply_layer(iter=i, name='X22', input=M[:, :, :, self.num_features:self.num_features*2])\n",
    "#             X_4 = self.__apply_layer(iter=i, name='X44', input=M[:, :, :, self.num_features*2:self.num_features*3])\n",
    "\n",
    "#             H_star = torch.concat([X_1, X_2, X_4], -1)\n",
    "#             # H_current = torch.sum(h_current, h_current.dim(), keepdim=True)\n",
    "#             H_star = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "#             X_1 = self.__apply_layer(iter=i, name='X1', input=H_star-H)\n",
    "#             X_2 = self.__apply_layer(iter=i, name='X2', input=H_star-H)\n",
    "#             X_4 = self.__apply_layer(iter=i, name='X4', input=H_star-H)\n",
    "\n",
    "#             stepM = self.get_submodule(target='iteration_'+str(i)+':stepM')\n",
    "#             M = self.__apply_layer(\n",
    "#                 iter=i,\n",
    "#                 name='Prox_M',\n",
    "#                 input=M-stepM*torch.concat([out_X1, out_X2, out_X4], -1)\n",
    "#             )\n",
    "\n",
    "#             X_1 = self.__apply_layer(iter=i, name='X111', input=M[:, :, :, 0:self.num_features])\n",
    "#             X_2 = self.__apply_layer(iter=i, name='X222', input=M[:, :, :, self.num_features:self.num_features*2])\n",
    "#             X_4 = self.__apply_layer(iter=i, name='X444', input=M[:, :, :, self.num_features*2:self.num_features*3])\n",
    "\n",
    "#             h_current = torch.concat([X_1, X_2, X_4], -1)\n",
    "#             # H_current = torch.sum(h_current, h_current.dim(), keepdim=True)\n",
    "#             H_current = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "#             O_current = image-H_current\n",
    "#             stepO = self.get_submodule(target='iteration_0:stepO')\n",
    "#             tmp = torch.concat([Z, stepO*O_current+(1.0-stepO)*O_previous], -1)\n",
    "#             # O_current, Z = self.__apply_layer(iter=i, name='Prox_O', input=tmp)\n",
    "#             O_current, Z = self.prox_O(tmp)\n",
    "\n",
    "#         final_out = O_current\n",
    "        \n",
    "#         return O_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class Unfolding(torch.nn.Module):\n",
    "\n",
    "\n",
    "#     def __init__(self, in_channels: int, num_features: int = 48, iterations: int = 10) -> None:\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.prox_O: Prox_O = Prox_O(in_channels=in_channels+num_features, num_features=num_features)\n",
    "#         self.prox_M: Prox_M = Prox_M(in_channels=num_features*3)\n",
    "#         self.stepO = torch.tensor(0.1, dtype=torch.double, requires_grad=True)\n",
    "#         self.stepM = torch.tensor(0.1, dtype=torch.double, requires_grad=True)\n",
    "#         self.num_features = num_features\n",
    "#         self.iterations = iterations\n",
    "\n",
    "#         #initial scope\n",
    "#         self.O_0 = torch.nn.Conv2d(in_channels=1, out_channels=num_features, kernel_size=3, padding=\"same\")\n",
    "\n",
    "#         self.conv_it = {}\n",
    "#         for i in range(iterations):\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X1\"] = torch.nn.Conv2d(in_channels=in_channels, out_channels=num_features, kernel_size=3, dilation=1, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X1\", module=self.conv_it[\"conv_it\"+str(i)+\"X1\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X2\"] = torch.nn.Conv2d(in_channels=in_channels, out_channels=num_features, kernel_size=3, dilation=2, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X2\", module=self.conv_it[\"conv_it\"+str(i)+\"X2\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X4\"] = torch.nn.Conv2d(in_channels=in_channels, out_channels=num_features, kernel_size=3, dilation=4, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X4\", module=self.conv_it[\"conv_it\"+str(i)+\"X4\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X11\"] = torch.nn.Conv2d(in_channels=num_features, out_channels=num_features, kernel_size=3, dilation=1, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X11\", module=self.conv_it[\"conv_it\"+str(i)+\"X11\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X22\"] = torch.nn.Conv2d(in_channels=num_features, out_channels=num_features, kernel_size=3, dilation=2, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X22\", module=self.conv_it[\"conv_it\"+str(i)+\"X22\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X44\"] = torch.nn.Conv2d(in_channels=num_features, out_channels=num_features, kernel_size=3, dilation=4, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X44\", module=self.conv_it[\"conv_it\"+str(i)+\"X44\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X111\"] = torch.nn.Conv2d(in_channels=num_features, out_channels=num_features, kernel_size=3, dilation=1, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X111\", module=self.conv_it[\"conv_it\"+str(i)+\"X111\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X222\"] = torch.nn.Conv2d(in_channels=num_features, out_channels=num_features, kernel_size=3, dilation=2, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X222\", module=self.conv_it[\"conv_it\"+str(i)+\"X222\"])\n",
    "#             self.conv_it[\"conv_it\"+str(i)+\"X444\"] = torch.nn.Conv2d(in_channels=num_features, out_channels=num_features, kernel_size=3, dilation=4, padding=\"same\", bias=False)\n",
    "#             self.add_module(name=\"conv_it\"+str(i)+\"X444\", module=self.conv_it[\"conv_it\"+str(i)+\"X444\"])\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#     def forward(self, J: torch.Tensor) -> torch.Tensor:\n",
    "#         #initial\n",
    "#         O_0 = self.O_0(J)\n",
    "#         a = [O_0,J]\n",
    "#         tmp = torch.concat([O_0,J],1)\n",
    "#         O_previous, Z = self.prox_O(tmp)\n",
    "#         H = J - O_previous\n",
    "\n",
    "#         #iteration 1\n",
    "#         X_1 = self.conv_it[\"conv_it\"+str(0)+\"X1\"](H)\n",
    "#         X_2 = self.conv_it[\"conv_it\"+str(0)+\"X2\"](H)\n",
    "#         X_4 = self.conv_it[\"conv_it\"+str(0)+\"X4\"](H)\n",
    "\n",
    "#         M = self.prox_M(torch.concat([X_1,X_2,X_4],1))\n",
    "\n",
    "#         X_1 = self.conv_it[\"conv_it\"+str(0)+\"X11\"](M[:,0:self.num_features,:,:])\n",
    "#         X_2 = self.conv_it[\"conv_it\"+str(0)+\"X22\"](M[:,self.num_features:self.num_features*2,:,:])\n",
    "#         X_4 = self.conv_it[\"conv_it\"+str(0)+\"X44\"](M[:,self.num_features*2:self.num_features*3,:,:])\n",
    "\n",
    "#         h_current = torch.concat([X_1,X_2,X_4],1)\n",
    "#         H_current = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "#         O_current = J - H_current\n",
    "\n",
    "#         tmp = torch.concat([Z, self.stepO * O_current + (1.-self.stepO) * O_previous],1)\n",
    "#         O_current, Z = self.prox_O(tmp)\n",
    "\n",
    "#         for i in range(1, self.iterations):\n",
    "#             O_previous = O_current\n",
    "#             H = J - O_previous\n",
    "\n",
    "#             X_1 = self.conv_it[\"conv_it\"+str(i)+\"X11\"](M[:,0:self.num_features,:,:])\n",
    "#             X_2 = self.conv_it[\"conv_it\"+str(i)+\"X22\"](M[:,self.num_features:self.num_features*2,:,:])\n",
    "#             X_4 = self.conv_it[\"conv_it\"+str(i)+\"X44\"](M[:,self.num_features*2:self.num_features*3,:,:])\n",
    "\n",
    "#             H_star = torch.concat([X_1,X_2,X_4],1)\n",
    "#             H_star = H_star.sum(1).unsqueeze(1)\n",
    "\n",
    "#             X_1 = self.conv_it[\"conv_it\"+str(i)+\"X1\"](H_star-H)\n",
    "#             X_2 = self.conv_it[\"conv_it\"+str(i)+\"X2\"](H_star-H)\n",
    "#             X_4 = self.conv_it[\"conv_it\"+str(i)+\"X4\"](H_star-H)\n",
    "\n",
    "#             M = self.prox_M(M - self.stepM * torch.concat([X_1,X_2,X_4],1))\n",
    "\n",
    "#             X_1 = self.conv_it[\"conv_it\"+str(i)+\"X111\"](M[:,0:self.num_features,:,:])\n",
    "#             X_2 = self.conv_it[\"conv_it\"+str(i)+\"X222\"](M[:,self.num_features:self.num_features*2,:,:])\n",
    "#             X_4 = self.conv_it[\"conv_it\"+str(i)+\"X444\"](M[:,self.num_features*2:self.num_features*3,:,:])\n",
    "\n",
    "#             h_current = torch.concat([X_1,X_2,X_4],1)\n",
    "#             H_current = h_current.sum(1).unsqueeze(1)\n",
    "\n",
    "\n",
    "#             O_current = J - H_current\n",
    "#             tmp = torch.concat([Z, self.stepO * O_current + (1.-self.stepO) * O_previous],1)\n",
    "#             O_current, Z = self.prox_O(tmp)\n",
    "\n",
    "\n",
    "#         return O_current\n",
    "\n",
    "\n",
    "#     def to(self, *args, **kwargs):\n",
    "#         self = super().to(*args, **kwargs)\n",
    "#         for i in self.conv_it:\n",
    "#           self.conv_it[i].to(*args, **kwargs)\n",
    "#         self.prox_O.to(*args, **kwargs)\n",
    "#         self.prox_M.to(*args, **kwargs)\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8af255b71a47211f3bbb11e1d8c056494be1673d7ecf3fd6691ea74e9e18340"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
